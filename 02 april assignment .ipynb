{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4151e49c-224e-4416-b5f3-6ff375915272",
   "metadata": {},
   "source": [
    "#Q1\n",
    "Purpose: Grid Search Cross-Validation (Grid Search CV) is a technique used to find the best hyperparameters for a machine learning model. It systematically tests a predefined set of hyperparameter values, searching through all possible combinations.\n",
    "\n",
    "How it works:\n",
    "\n",
    "Define a hyperparameter grid, specifying the values to be tested for each hyperparameter.\n",
    "\n",
    "The grid search algorithm trains the model for each combination of hyperparameter values using cross-validation.\n",
    "\n",
    "It evaluates the model's performance based on a specified metric.\n",
    "\n",
    "The combination of hyperparameter values that gives the best performance is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f909535f-87ab-4230-9a18-8563334c5b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(rf_classifier, param_grid, cv=3, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameter values\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c303951-ff24-42df-90ec-a38eadf367ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c042b2b3-c7af-4aa0-9f56-1fced6ab1b7a",
   "metadata": {},
   "source": [
    "#Q2\n",
    "Difference:\n",
    "\n",
    "Grid Search CV: It exhaustively searches through all possible combinations of hyperparameter values defined in a grid. It's computationally expensive but ensures a thorough exploration of the hyperparameter space.\n",
    "\n",
    "Randomized Search CV: It randomly samples a fixed number of hyperparameter combinations from the specified hyperparameter space. It's computationally less expensive but may not guarantee a thorough exploration.\n",
    "\n",
    "When to choose:\n",
    "\n",
    "Use Grid Search CV when:\n",
    "\n",
    "The hyperparameter search space is not too large.\n",
    "You have sufficient computational resources.\n",
    "\n",
    "Use Randomized Search CV when:\n",
    "\n",
    "The hyperparameter search space is large.\n",
    "You want to perform a quick exploration of the hyperparameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b0f5f53-2737-4a58-916e-e52c59b60a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters (Randomized Search): {'n_estimators': 200, 'min_samples_split': 10, 'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Randomized Search\n",
    "random_search = RandomizedSearchCV(rf_classifier, param_distributions=param_grid, n_iter=10, cv=3, scoring='accuracy')\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameter values\n",
    "print(\"Best Hyperparameters (Randomized Search):\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d940923b-210f-4f05-ada8-d0f6ae76f34b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e37dc8f-0bc2-47f4-a1a2-ed629af40785",
   "metadata": {},
   "source": [
    "#Q3\n",
    "Data Leakage: Data leakage occurs when information from the test set is used to train a model, leading to overly optimistic performance estimates. It can result in models that perform well on the test set but fail to generalize to new, unseen data.\n",
    "\n",
    "Example: Let's say you're building a credit risk model, and you accidentally include future information about a customer's credit history in the training set (e.g., including information about whether a customer defaulted on a loan after the current loan was approved). The model might learn patterns related to the future outcome, making it seem more accurate during training but less effective on new applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014717fc-d358-4757-ae11-350bcf5269b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a075074-34b8-4833-8c94-20f7d97507e1",
   "metadata": {},
   "source": [
    "#Q4\n",
    "Preventing Data Leakage:\n",
    "\n",
    "Split Data Properly: Ensure a clear separation between training and test sets before any preprocessing.\n",
    "\n",
    "Feature Engineering: Create features only using information available at the time of prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31ee8276-b00a-4182-9540-6806544a78c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "# Create a DataFrame\n",
    "X = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "y = breast_cancer.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train a RandomForestClassifier on the training set\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance on the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on the test set:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a84822c-895d-4fd9-bd35-abb32254fdc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6d41cea-3b84-41c0-98f2-7f6675feada7",
   "metadata": {},
   "source": [
    "#Q5\n",
    "Confusion Matrix: A confusion matrix is a table that summarizes the performance of a classification model. It shows the counts of true positive, true negative, false positive, and false negative predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04ddbf87-2b70-4ba9-b07b-24f3ef52c0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[19  0]\n",
      " [ 0 11]]\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Binary classification (class 2 vs. not class 2)\n",
    "y_binary = (y == 2).astype(int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a logistic regression model\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# Create a confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62b1f5e-aea7-45c2-852d-8742d0223dee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30c6259f-de46-4d3b-9b46-bcf03d742da4",
   "metadata": {},
   "source": [
    "#Q6\n",
    "Precision: Precision is the ratio of correctly predicted positive observations to the total predicted positives. It focuses on the accuracy of the positive predictions.\n",
    "\n",
    "Precision=TP/TP+FP\n",
    " \n",
    "\n",
    "Recall (Sensitivity or True Positive Rate): Recall is the ratio of correctly predicted positive observations to the total actual positives. It focuses on how well the model captures all the positive instances.\n",
    "\n",
    "Recall=TP/TP+FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ff7b93-178d-473c-84a2-e240cbe05e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e40b3152-03fc-4c37-bab4-80419699e1de",
   "metadata": {},
   "source": [
    "#Q7\n",
    "Interpretation:\n",
    "\n",
    "True Positive (TP): Instances correctly predicted as positive.\n",
    "\n",
    "True Negative (TN): Instances correctly predicted as negative.\n",
    "\n",
    "False Positive (FP): Instances incorrectly predicted as positive (Type I error).\n",
    "\n",
    "False Negative (FN): Instances incorrectly predicted as negative (Type II error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a85a5e1-7b9f-4eae-813c-a57e6e269355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[19  0]\n",
      " [ 0 11]]\n",
      "True Positive: 11\n",
      "True Negative: 19\n",
      "False Positive: 0\n",
      "False Negative: 0\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Interpretation\n",
    "print(\"True Positive:\", cm[1, 1])\n",
    "print(\"True Negative:\", cm[0, 0])\n",
    "print(\"False Positive:\", cm[0, 1])\n",
    "print(\"False Negative:\", cm[1, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f21cb0-97dd-4012-856e-2512770e2fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b11ab72-59b4-4d5e-9afa-6c3b232e2af6",
   "metadata": {},
   "source": [
    "#Q8\n",
    "common metrics:\n",
    "Accuracy,\n",
    "Precision,\n",
    "Recall (Sensitivity),\n",
    "Specificity,\n",
    "F1 Score,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6456d5cd-e48f-4d67-a572-230ea9dddac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e0efea-fa96-4a82-9f57-21e60166ca89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "762e0009-a87e-405c-94e6-7e1ffcf5194b",
   "metadata": {},
   "source": [
    "#Q9\n",
    "Accuracy: Overall correctness of the model \n",
    "\n",
    "Confusion Matrix: Provides a detailed breakdown of correct and incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5811e95b-4474-45b2-9b31-16c35dc88f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[19  0]\n",
      " [ 0 11]]\n"
     ]
    }
   ],
   "source": [
    "#9\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeddb29-c167-41c0-8512-c2828e77a058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1b88515-1f48-49e4-ae5e-b47b48162e10",
   "metadata": {},
   "source": [
    "#Q10\n",
    "Identification of Biases or Limitations:\n",
    "\n",
    "Class Imbalance: Check if there is a significant imbalance between classes.\n",
    "\n",
    "Bias Toward Majority Class: A model might perform well on the majority class but poorly on the minority class.\n",
    "\n",
    "False Positive/Negative Rates: Analyze errors and their impact on different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c60addc-2a00-4a74-a398-bddfa6f8b97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[3 2]\n",
      " [1 4]]\n",
      "True Positive: 4\n",
      "True Negative: 3\n",
      "False Positive: 2\n",
      "False Negative: 1\n",
      "Accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Assuming y_test and y_pred are NumPy arrays\n",
    "y_test = np.array([1, 0, 1, 1, 0, 0, 1, 1, 0, 0])\n",
    "y_pred = np.array([1, 0, 1, 1, 0, 1, 1, 0, 0, 1])\n",
    "\n",
    "# Create a confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Interpretation\n",
    "tp = np.sum((y_test == 1) & (y_pred == 1))\n",
    "tn = np.sum((y_test == 0) & (y_pred == 0))\n",
    "fp = np.sum((y_test == 0) & (y_pred == 1))\n",
    "fn = np.sum((y_test == 1) & (y_pred == 0))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Interpretation\n",
    "print(\"True Positive:\", tp)\n",
    "print(\"True Negative:\", tn)\n",
    "print(\"False Positive:\", fp)\n",
    "print(\"False Negative:\", fn)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f13d03-40e4-4515-a480-3b6f5a0824c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
