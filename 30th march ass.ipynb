{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ed56cfc-5017-4b39-8a4b-ea7a0d0d6269",
   "metadata": {},
   "source": [
    "Q1\n",
    "Elastic Net Regression is a linear regression technique that combines both L1 (Lasso) and L2 (Ridge) regularization terms in its objective function. The regularization term in Elastic Net is a linear combination of the L1 and L2 penalties. This combination allows Elastic Net to address some limitations of Lasso and Ridge regression, providing a balance between feature selection and handling correlated features.\n",
    "\n",
    "Elastic Net objective function:\n",
    "Cost=OLS Cost+λ1 ∑i=1 ∣wi∣+λ2 ∑ i=1 wi^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad0b684-d3d1-4849-829b-c8b9bc697d30",
   "metadata": {},
   "source": [
    "Q2\n",
    "The optimal values of the regularization parameters (1λ and λ2) in Elastic Net are typically chosen using cross-validation. Grid search or randomized search over a range of values for both parameters can be performed, and the combination with the best performance is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56e0b51b-56c9-4fb7-846f-712d7ffa4e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha: 0.1\n",
      "Optimal l1_ratio: 0.1\n"
     ]
    }
   ],
   "source": [
    "#Q2\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the Diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create Elastic Net model\n",
    "elastic_net = ElasticNet()\n",
    "\n",
    "# Define a range of alpha and l1_ratio values to test\n",
    "param_grid = {'alpha': [0.1, 1.0, 10.0],\n",
    "              'l1_ratio': [0.1, 0.5, 0.7, 0.9]}\n",
    "\n",
    "# Perform GridSearchCV to find the optimal alpha and l1_ratio\n",
    "grid_search = GridSearchCV(elastic_net, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best alpha and l1_ratio from the grid search\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_l1_ratio = grid_search.best_params_['l1_ratio']\n",
    "\n",
    "print(f\"Optimal alpha: {best_alpha}\")\n",
    "print(f\"Optimal l1_ratio: {best_l1_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ee807e-2d49-4e6d-8f73-f61293ceeb76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0364b773-6ead-46a9-9021-476017eefb9b",
   "metadata": {},
   "source": [
    "Q3. What are the advantages and disadvantages of Elastic Net Regression?\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Balances L1 and L2 regularization: Combines the feature selection ability of Lasso with the ability of Ridge to handle correlated features.\n",
    "Handles multicollinearity: Effective when dealing with highly correlated features.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Two hyperparameters: Requires tuning of two hyperparameters (1λ and λ2), making the model selection process more complex.\n",
    "Computationally more expensive: More computationally intensive compared to Lasso and Ridge due to the additional term in the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efca7ce-7167-4117-aa19-58e0ff83721e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91f12457-11d3-48a0-b459-751a94ad1b7a",
   "metadata": {},
   "source": [
    "Q4. What are some common use cases for Elastic Net Regression?\n",
    "\n",
    "Elastic Net Regression is commonly used in scenarios where:\n",
    "\n",
    "The dataset has many features, some of which may be irrelevant or redundant.\n",
    "Features are correlated, and you want to prevent multicollinearity issues.\n",
    "A balance between feature selection and regularization is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc83ac8-6c36-4854-87f1-d37826311423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac209e06-9b56-41be-b972-f482a7c4fee4",
   "metadata": {},
   "source": [
    "Q5. How do you interpret the coefficients in Elastic Net Regression?\n",
    "\n",
    "Interpreting coefficients in Elastic Net is similar to interpreting coefficients in linear regression. The magnitude of each coefficient represents the impact of the corresponding feature on the target variable, considering the effects of both L1 and L2 regularization.\n",
    "\n",
    "Q6. How do you handle missing values when using Elastic Net Regression?\n",
    "\n",
    "Handling missing values is crucial in any regression model. Common approaches include:\n",
    "\n",
    "Imputation: Fill missing values with the mean, median, or another suitable value.\n",
    "Feature engineering: Create an indicator variable to represent the presence of missing values in a particular feature.\n",
    "Advanced imputation methods: Use more sophisticated imputation methods, such as K-nearest neighbors imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260ef55c-bc23-478e-9746-fce7a9d6f322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd0b82aa-8d48-4044-8bb9-04dd702e17b3",
   "metadata": {},
   "source": [
    "Q7Elastic Net inherently performs feature selection by driving some coefficients to exactly zero. The degree of sparsity in the model depends on the strength of the L1 penalty (λ1). A larger λ1 encourages more coefficients to become zero, leading to a sparser model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "880be1fc-1c10-41fe-af27-c22baa40243a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected alpha: 0.18943499524127297\n",
      "Selected l1_ratio: 0.5\n",
      "Selected coefficients: [ 1.89206516 -9.96604966 24.43510742 15.49023732 -5.82582946 -3.69773061\n",
      " -8.879132    7.06088057 19.34684644  3.56025388]\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "# Create Elastic Net model with cross-validated alpha and l1_ratio\n",
    "elastic_net_cv = ElasticNetCV(cv=5)\n",
    "elastic_net_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Access the selected alpha and l1_ratio\n",
    "selected_alpha = elastic_net_cv.alpha_\n",
    "selected_l1_ratio = elastic_net_cv.l1_ratio_\n",
    "\n",
    "# Access the coefficients\n",
    "coefficients = elastic_net_cv.coef_\n",
    "\n",
    "print(f\"Selected alpha: {selected_alpha}\")\n",
    "print(f\"Selected l1_ratio: {selected_l1_ratio}\")\n",
    "print(\"Selected coefficients:\", coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0eab43-68f5-4b4f-b6e6-e86bb935cb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d789a52-479c-40d1-97ec-1f00830de953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8\n",
    "#Pickle is a Python module for serializing and deserializing objects. You can use it to save and load trained models.\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Train Elastic Net model\n",
    "elastic_net_model = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio)\n",
    "elastic_net_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save the model to a file\n",
    "with open('elastic_net_model.pkl', 'wb') as file:\n",
    "    pickle.dump(elastic_net_model, file)\n",
    "\n",
    "# Load the model from the file\n",
    "with open('elastic_net_model.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "predictions = loaded_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b0a5b3-640a-4e97-9ca6-9a83d411a022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce10258f-4472-4298-8ec4-0c89d5245367",
   "metadata": {},
   "source": [
    "Q9. What is the purpose of pickling a model in machine learning?\n",
    "\n",
    "Pickling a model allows you to:\n",
    "\n",
    "Save: Store a trained model to disk for later use or sharing with others.\n",
    "\n",
    "Deploy: Use the model in production environments without retraining.\n",
    "\n",
    "Versioning: Maintain a record of model versions for reproducibility.\n",
    "\n",
    "These practices are essential for ensuring consistent and reproducible machine learning workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e754f386-7fb3-4b1d-ba06-6819f43ffc00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
