{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9562080-f6c7-4357-8985-d13e2c9cf81e",
   "metadata": {},
   "source": [
    "#Q1. What is Random Forest Regressor? \n",
    "\n",
    "Random Forest Regressor is an ensemble learning method based on the principle of constructing a multitude of decision trees at training time and outputting the average prediction of the individual trees for regression tasks. It builds multiple decision trees and merges them together to get a more accurate and stable prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ccc2c1-42d1-4688-a842-c3600cc8439e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.7741987430982417\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Generate some random data for demonstration\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1)\n",
    "y = 4 * (X.squeeze()) + np.random.randn(100)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = rf_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6b4e14-fde8-4615-bb57-80f48d548f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "403b4006-0440-43ea-aadb-bfeb10d05aac",
   "metadata": {},
   "source": [
    "#Q2 How does Random Forest Regressor reduce the risk of overfitting? \n",
    "\n",
    "Random Forest Regressor reduces overfitting by averaging the predictions of multiple decision trees, each trained on different subsets of the data. This diversity helps the model generalize well to new, unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d085715-97e6-49f3-a0ee-9fa64242abd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.6834414059910386\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "# Using the same data as before\n",
    "# ...\n",
    "\n",
    "# Create a Random Forest Regressor with max_depth to control overfitting\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = rf_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1b822b-9868-4b84-8cdd-1253b0adc4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f25e652-ba7b-43f9-89b7-50914867ebec",
   "metadata": {},
   "source": [
    "#Q3 How does Random Forest Regressor aggregate the predictions of multiple decision trees?\n",
    "\n",
    "Random Forest Regressor aggregates predictions by averaging them for regression tasks. For classification, it can use voting or averaging probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29d1eecd-95e0-43f6-b0b8-be55c7646aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error with Aggregated Predictions: 0.7741987430982417\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "# Using the same data as before\n",
    "# ...\n",
    "\n",
    "# Create a Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Access individual tree predictions (for the first tree)\n",
    "tree_predictions = rf_regressor.estimators_[0].predict(X_test)\n",
    "\n",
    "# Average predictions across all trees\n",
    "average_predictions = np.mean([tree.predict(X_test) for tree in rf_regressor.estimators_], axis=0)\n",
    "\n",
    "# Evaluate the model using average predictions\n",
    "mse = mean_squared_error(y_test, average_predictions)\n",
    "print(f\"Mean Squared Error with Aggregated Predictions: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15fd641-c9d4-4863-a93a-4e3659057f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "149943e1-b305-4da5-84dc-9839f5df83d3",
   "metadata": {},
   "source": [
    "#Q4 What are the hyperparameters of Random Forest Regressor? \n",
    "\n",
    "Some key hyperparameters of RandomForestRegressor include:\n",
    "\n",
    "n_estimators: Number of trees in the forest.\n",
    "\n",
    "max_depth: Maximum depth of the trees.\n",
    "\n",
    "min_samples_split: Minimum number of samples required to split an internal node.\n",
    "\n",
    "min_samples_leaf: Minimum number of samples required to be at a leaf node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10482ce8-00d3-47ea-a3ff-99accf7e495d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.7704437570952613\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "# Using the same data as before\n",
    "# ...\n",
    "\n",
    "# Create a Random Forest Regressor with specified hyperparameters\n",
    "rf_regressor = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = rf_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a7e9f3-a8ad-4dfc-a193-a260f6981670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ab11435-aa51-45d8-9c3b-000f43ee5bfc",
   "metadata": {},
   "source": [
    "#Q5 What is the difference between Random Forest Regressor and Decision Tree Regressor?\n",
    "\n",
    "The main differences between Random Forest Regressor and Decision Tree Regressor are:\n",
    "\n",
    "Ensemble vs. Single Tree: Random Forest is an ensemble of multiple decision trees, while Decision Tree Regressor consists of a single decision tree.\n",
    "\n",
    "Overfitting: Random Forest is less prone to overfitting compared to a single Decision Tree, as it averages predictions across multiple trees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5745106e-b0bc-4d31-8f5a-306e77c44b49",
   "metadata": {},
   "source": [
    "#Q6 What are the advantages and disadvantages of Random Forest Regressor?\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Effective for both regression and classification tasks.\n",
    "\n",
    "Robust to overfitting due to the ensemble nature.\n",
    "\n",
    "Handles missing values well.\n",
    "\n",
    "Provides feature importance.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Can be computationally expensive.\n",
    "\n",
    "Harder to interpret compared to a single decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a40a29-90dd-4176-8cd8-c39473fb1717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fa4fa67-9774-4423-92e8-77f5b52e8967",
   "metadata": {},
   "source": [
    "#Q7 What is the output of Random Forest Regressor?\n",
    "\n",
    "The output of a Random Forest Regressor is a continuous prediction for each input sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4a3051b-c093-447a-be92-67a8755adbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for new data:\n",
      "[3.24493307 0.40735797]\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "# Using the same data as before\n",
    "# ...\n",
    "\n",
    "# Make predictions on new data\n",
    "new_data = np.array([[0.8], [0.2]])\n",
    "new_predictions = rf_regressor.predict(new_data)\n",
    "\n",
    "print(\"Predictions for new data:\")\n",
    "print(new_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963beff4-9ce7-4789-bb95-c9375bb64169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a0c57c8-2ec4-461d-acc7-f42268c20d7e",
   "metadata": {},
   "source": [
    "#Q8  Can Random Forest Regressor be used for classification tasks? \n",
    "\n",
    "Yes, Random Forest can be used for classification tasks as well. It aggregates the votes or probabilities from individual trees to make a final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33bbd19c-ddda-4ca1-851e-9ddb171069a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load Iris dataset for classification\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c91e753-90d9-48ae-a2ac-03f22c2426b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
