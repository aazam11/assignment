{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5184da2-554f-419c-beed-dc1eccf27504",
   "metadata": {},
   "source": [
    "#Q1\n",
    "In the context of clustering evaluation, homogeneity and completeness are two metrics used to assess the quality of a clustering solution.\n",
    "\n",
    "Homogeneity:\n",
    "\n",
    "Homogeneity measures the degree to which each cluster contains only members of a single class. In other words, it evaluates whether the clusters are made up of data points that belong to the same class or category.\n",
    "The homogeneity score ranges from 0 to 1, where 1 indicates perfect homogeneity.\n",
    "\n",
    "Completeness:\n",
    "Completeness measures the degree to which all members of a given class are assigned to the same cluster. It evaluates whether all data points belonging to the same class are grouped together in a single cluster.\n",
    "Like homogeneity, the completeness score also ranges from 0 to 1, with 1 indicating perfect completeness.\n",
    "\n",
    "These metrics are often used together, and a balance between homogeneity and completeness is desired for a good clustering solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52305064-53e2-437e-a866-ba31b6a6c807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity Score: 1.0000\n",
      "Completeness Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "from sklearn.metrics import homogeneity_score, completeness_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Generate synthetic data with 3 clusters\n",
    "X, y = make_blobs(n_samples=300, centers=3, random_state=42)\n",
    "\n",
    "# Apply KMeans clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "labels = kmeans.fit_predict(X)\n",
    "\n",
    "# Calculate homogeneity and completeness\n",
    "homogeneity = homogeneity_score(y, labels)\n",
    "completeness = completeness_score(y, labels)\n",
    "\n",
    "print(f'Homogeneity Score: {homogeneity:.4f}')\n",
    "print(f'Completeness Score: {completeness:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfbb328-dc8f-4a14-aaee-36e36f83212c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09d96c98-2bd5-4200-891a-da095019995c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#Q2\n",
    "The V-measure is a metric used for clustering evaluation that combines homogeneity and completeness into a single score. It provides a balance between these two aspects of clustering quality. The V-measure is the harmonic mean of homogeneity and completeness, and it is defined as follows:\n",
    "\n",
    "V= 2×homogeneity×completeness/homogeneity+completeness \n",
    "\n",
    "The V-measure ranges from 0 to 1, with 1 indicating a perfect clustering solution where clusters are both homogeneous and complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e59b30a-119a-45ff-a997-cd6db534e3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V-measure Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "from sklearn.metrics import v_measure_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Generate synthetic data with 3 clusters\n",
    "X, y = make_blobs(n_samples=300, centers=3, random_state=42)\n",
    "\n",
    "# Apply KMeans clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "labels = kmeans.fit_predict(X)\n",
    "\n",
    "# Calculate V-measure\n",
    "v_measure = v_measure_score(y, labels)\n",
    "\n",
    "print(f'V-measure Score: {v_measure:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3946f053-204c-4aa4-af4d-22b4bd064d0f",
   "metadata": {},
   "source": [
    "the V-measure is a useful metric that balances the trade-off between homogeneity and completeness in clustering evaluation. It is particularly valuable when you want a single measure to capture the overall quality of a clustering solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf0d97a-672d-43f2-955d-f408eeb11687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db7268ff-e03e-4604-96a9-d5a3f794134d",
   "metadata": {},
   "source": [
    "#Q3\n",
    "The Silhouette Coefficient is a metric used to evaluate the quality of a clustering result. It measures how well-separated clusters are and takes into account both the cohesion within clusters and the separation between clusters. The Silhouette Coefficient for a single data point is defined as:\n",
    "\n",
    "s(i)=b(i)−a(i)/max{a(i),b(i)}\n",
    "\n",
    "Where:\n",
    "\n",
    "a(i) is the average distance from the \n",
    "\n",
    "i-th data point to other data points in the same cluster.\n",
    "\n",
    "b(i) is the smallest average distance from the \n",
    "\n",
    "i-th data point to data points in a different cluster.\n",
    "The Silhouette Coefficient for the entire clustering solution is the average of the silhouette scores for all data points.\n",
    "\n",
    "The range of Silhouette Coefficient values is between -1 and 1. A higher value indicates better-defined clusters, with a score close to 1 suggesting well-separated clusters, a score around 0 indicating overlapping clusters, and negative values indicating that data points might be assigned to the wrong clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7e2f6b3-d807-48bf-90c8-ab04d3a0e897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 2, Silhouette Coefficient: 0.7049\n",
      "Number of clusters: 3, Silhouette Coefficient: 0.8480\n",
      "Number of clusters: 4, Silhouette Coefficient: 0.6630\n",
      "Number of clusters: 5, Silhouette Coefficient: 0.5014\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Generate synthetic data with 3 clusters\n",
    "X, _ = make_blobs(n_samples=300, centers=3, random_state=42)\n",
    "\n",
    "# Apply KMeans clustering with different number of clusters\n",
    "for n_clusters in range(2, 6):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    \n",
    "    # Calculate Silhouette Coefficient\n",
    "    silhouette_avg = silhouette_score(X, labels)\n",
    "    \n",
    "    print(f'Number of clusters: {n_clusters}, Silhouette Coefficient: {silhouette_avg:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c677c1-56bd-4c53-a2e3-821a66d918c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91e8e03b-5163-424f-9608-5bc6983279bb",
   "metadata": {},
   "source": [
    "#Q4\n",
    "The Davies-Bouldin Index is a metric used for evaluating the quality of a clustering result. It provides a measure of the compactness and separation of clusters in a clustering solution. The index is calculated based on the pairwise similarity between clusters, considering both intra-cluster cohesion and inter-cluster separation. Lower Davies-Bouldin Index values indicate better clustering solutions.\n",
    "\n",
    "The range of Davies-Bouldin Index values is not bounded, but lower values indicate better clustering solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bbfc0ff-eca4-4207-812a-1d99163118be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 2, Davies-Bouldin Index: 0.4360\n",
      "Number of clusters: 3, Davies-Bouldin Index: 0.2123\n",
      "Number of clusters: 4, Davies-Bouldin Index: 0.7068\n",
      "Number of clusters: 5, Davies-Bouldin Index: 0.9802\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Generate synthetic data with 3 clusters\n",
    "X, _ = make_blobs(n_samples=300, centers=3, random_state=42)\n",
    "\n",
    "# Apply KMeans clustering with different number of clusters\n",
    "for n_clusters in range(2, 6):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    \n",
    "    # Calculate Davies-Bouldin Index\n",
    "    db_index = davies_bouldin_score(X, labels)\n",
    "    \n",
    "    print(f'Number of clusters: {n_clusters}, Davies-Bouldin Index: {db_index:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41013667-7b19-4045-ab6e-ac4f76f2007a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "935e5fce-718c-48bf-b5b7-b3a3043c93a9",
   "metadata": {},
   "source": [
    "#Q5\n",
    "Yes, it is possible for a clustering result to have high homogeneity but low completeness. Homogeneity measures whether all clusters contain only members of a single class, while completeness measures whether all members of a given class are assigned to the same cluster.\n",
    "\n",
    "Consider a scenario with three classes (A, B, and C) and two clusters (Cluster 1 and Cluster 2):\n",
    "\n",
    "Cluster 1: Contains all instances of Class A.\n",
    "\n",
    "Cluster 2: Contains instances from Class B and Class C.\n",
    "\n",
    "In this case, Cluster 1 is perfectly homogeneous as it contains only instances of Class A. However, it is not complete because instances from Class B and Class C are not assigned to Cluster 1. Therefore, completeness is low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "189d8fc3-0d37-4ae1-b73b-751fda884e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.5794\n",
      "Completeness: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "from sklearn.metrics import homogeneity_score, completeness_score\n",
    "\n",
    "# Ground truth labels\n",
    "true_labels = [0, 1, 2, 0, 1, 2]\n",
    "\n",
    "# Cluster assignments\n",
    "cluster_assignments = [0, 1, 1, 0, 1, 1]\n",
    "\n",
    "homogeneity = homogeneity_score(true_labels, cluster_assignments)\n",
    "completeness = completeness_score(true_labels, cluster_assignments)\n",
    "\n",
    "print(f'Homogeneity: {homogeneity:.4f}')\n",
    "print(f'Completeness: {completeness:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e28ffad-d4a2-49bb-a6ed-d67523523129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a9bacb4-ebe9-4a61-98d0-9698275043d7",
   "metadata": {},
   "source": [
    "#Q6\n",
    "\n",
    "The V-measure can be used to determine the optimal number of clusters by comparing the V-measure scores for different cluster numbers. The number of clusters that maximizes the V-measure is considered the optimal choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fa17972-b11f-4e62-9bdd-d9c789d61319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 2, V-measure: 0.7337\n",
      "Number of clusters: 3, V-measure: 1.0000\n",
      "Number of clusters: 4, V-measure: 0.9091\n",
      "Number of clusters: 5, V-measure: 0.8279\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "from sklearn.metrics import v_measure_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Generate synthetic data with ground truth labels\n",
    "X, true_labels = make_blobs(n_samples=300, centers=3, random_state=42)\n",
    "\n",
    "# Evaluate V-measure for different cluster numbers\n",
    "for n_clusters in range(2, 6):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_assignments = kmeans.fit_predict(X)\n",
    "    \n",
    "    v_measure = v_measure_score(true_labels, cluster_assignments)\n",
    "    \n",
    "    print(f'Number of clusters: {n_clusters}, V-measure: {v_measure:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f13be62-68db-4f1f-8a5b-70ae4ea32b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87f8438e-8bdd-44bc-bae2-11e013491953",
   "metadata": {},
   "source": [
    "#Q7\n",
    "\n",
    "Advantages:\n",
    "Interpretability: Silhouette Coefficient is easy to understand and interpret.\n",
    "\n",
    "No dependence on ground truth: Unlike some metrics, Silhouette Coefficient does not depend on ground truth labels, making it applicable in unsupervised scenarios.\n",
    "\n",
    "Disadvantages:\n",
    "Sensitive to shape and density: Silhouette Coefficient may not perform well when dealing with clusters of varying shapes and densities.\n",
    "\n",
    "Does not handle well varying cluster sizes: Silhouette Coefficient may not be suitable for clusters with significantly different sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88bab98b-7097-441d-aab4-bea97329a4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 2, Silhouette Coefficient: 0.7049\n",
      "Number of clusters: 3, Silhouette Coefficient: 0.8480\n",
      "Number of clusters: 4, Silhouette Coefficient: 0.6630\n",
      "Number of clusters: 5, Silhouette Coefficient: 0.5014\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Generate synthetic data with 3 clusters\n",
    "X, _ = make_blobs(n_samples=300, centers=3, random_state=42)\n",
    "\n",
    "# Apply KMeans clustering with different number of clusters\n",
    "for n_clusters in range(2, 6):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    \n",
    "    # Calculate Silhouette Coefficient\n",
    "    silhouette_avg = silhouette_score(X, labels)\n",
    "    \n",
    "    print(f'Number of clusters: {n_clusters}, Silhouette Coefficient: {silhouette_avg:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc8e954-3bbd-4e02-b968-e5eb5c958e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86504cd2-0c1d-4ede-b772-850e1a28ef64",
   "metadata": {},
   "source": [
    "#Q8\n",
    "Limitations:\n",
    "\n",
    "Sensitive to dimensionality: The Davies-Bouldin Index tends to perform poorly in high-dimensional spaces.\n",
    "\n",
    "Assumes spherical clusters: It assumes that clusters are spherical, which may not be true in real-world data.\n",
    "\n",
    "Dependent on cluster shapes: Performance may vary based on the shapes and sizes of the clusters.\n",
    "\n",
    "Overcoming Limitations:\n",
    "\n",
    "Dimensionality reduction: Perform dimensionality reduction techniques before applying the Davies-Bouldin Index.\n",
    "\n",
    "Consider other indices: Combine the Davies-Bouldin Index with other metrics for a more comprehensive evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c46a2f89-31ad-4732-ae8b-c939b150caf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 2, Davies-Bouldin Index: 0.4360\n",
      "Number of clusters: 3, Davies-Bouldin Index: 0.2123\n",
      "Number of clusters: 4, Davies-Bouldin Index: 0.7068\n",
      "Number of clusters: 5, Davies-Bouldin Index: 0.9802\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Generate synthetic data with 3 clusters\n",
    "X, _ = make_blobs(n_samples=300, centers=3, random_state=42)\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Apply KMeans clustering with different number of clusters\n",
    "for n_clusters in range(2, 6):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    labels = kmeans.fit_predict(X_pca)\n",
    "    \n",
    "    # Calculate Davies-Bouldin Index\n",
    "    db_index = davies_bouldin_score(X_pca, labels)\n",
    "    \n",
    "    print(f'Number of clusters: {n_clusters}, Davies-Bouldin Index: {db_index:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055f8708-eadf-4c05-a7bd-b1d8bc5c8216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54f8d79a-5cc7-4c94-813a-608133afbe6f",
   "metadata": {},
   "source": [
    "#Q9\n",
    "\n",
    "Homogeneity: Measures the extent to which each cluster contains only members of a single class.\n",
    "\n",
    "Completeness: Measures the extent to which all members of a given class are assigned to the same cluster.\n",
    "\n",
    "V-measure: Represents the harmonic mean of homogeneity and completeness.\n",
    "\n",
    "They can have different values for the same clustering result if the clusters are not equally balanced in terms of class distribution. For example, if a clustering solution perfectly separates one class into its own cluster but mixes other classes into the remaining clusters, homogeneity may be high while completeness may be low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ac36bf3-66bf-4d5f-93de-d55b397d6ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity Score: 1.0000\n",
      "Completeness Score: 1.0000\n",
      "V-measure Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#9\n",
    "from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Generate synthetic data with 3 clusters\n",
    "X, y = make_blobs(n_samples=300, centers=3, random_state=42)\n",
    "\n",
    "# Apply KMeans clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "labels = kmeans.fit_predict(X)\n",
    "\n",
    "# Calculate homogeneity, completeness, and V-measure\n",
    "homogeneity = homogeneity_score(y, labels)\n",
    "completeness = completeness_score(y, labels)\n",
    "v_measure = v_measure_score(y, labels)\n",
    "\n",
    "print(f'Homogeneity Score: {homogeneity:.4f}')\n",
    "print(f'Completeness Score: {completeness:.4f}')\n",
    "print(f'V-measure Score: {v_measure:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bf6f62-42de-4379-a94c-76ed91499a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4408df5-be79-419e-9190-7b6fdb6602d5",
   "metadata": {},
   "source": [
    "#Q10\n",
    "The Silhouette Coefficient can be used to compare the quality of different clustering algorithms on the same dataset by calculating the Silhouette Coefficient for each algorithm and choosing the one with the highest average score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d50a3582-6dc6-4b1d-9f60-9fd2520524ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans Silhouette Coefficient: 0.8480\n",
      "AgglomerativeClustering Silhouette Coefficient: 0.8480\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "\n",
    "# Generate synthetic data with 3 clusters\n",
    "X, _ = make_blobs(n_samples=300, centers=3, random_state=42)\n",
    "\n",
    "# Apply KMeans clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(X)\n",
    "kmeans_silhouette = silhouette_score(X, kmeans_labels)\n",
    "\n",
    "# Apply AgglomerativeClustering\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=3)\n",
    "agg_labels = agg_clustering.fit_predict(X)\n",
    "agg_silhouette = silhouette_score(X, agg_labels)\n",
    "\n",
    "print(f'KMeans Silhouette Coefficient: {kmeans_silhouette:.4f}')\n",
    "print(f'AgglomerativeClustering Silhouette Coefficient: {agg_silhouette:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e83a09d-958c-4751-b598-7dfd5c48f2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f1ff9b3-a609-47e5-b3e3-40bac67feda4",
   "metadata": {},
   "source": [
    "#Q11\n",
    "Davies-Bouldin Index: Measures the average similarity-to-dissimilarity ratio between each cluster and its most similar cluster.\n",
    "\n",
    "The index calculates the average ratio of the distance within a cluster to the distance between clusters. Lower values indicate better separation and compactness. The assumption is that clusters should be both well-separated and compact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef24f2bc-d14d-4ec1-ba67-62b0a42ea9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 0.2123\n"
     ]
    }
   ],
   "source": [
    "#11\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Generate synthetic data with 3 clusters\n",
    "X, _ = make_blobs(n_samples=300, centers=3, random_state=42)\n",
    "\n",
    "# Apply KMeans clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "labels = kmeans.fit_predict(X)\n",
    "\n",
    "# Calculate Davies-Bouldin Index\n",
    "db_index = davies_bouldin_score(X, labels)\n",
    "\n",
    "print(f'Davies-Bouldin Index: {db_index:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a9364f-e499-46e8-8a25-c364b75db5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54ccff80-739b-4ab3-8655-4c3bda1ef82b",
   "metadata": {},
   "source": [
    "#Q12\n",
    "\n",
    "Yes, the Silhouette Coefficient can be used to evaluate hierarchical clustering algorithms. When using hierarchical clustering, you need to consider the cluster assignments at different linkage levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfd5bce9-8b3f-4af8-b4ad-f94a7434a509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgglomerativeClustering Silhouette Coefficient: 0.8480\n"
     ]
    }
   ],
   "source": [
    "#12\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Generate synthetic data with 3 clusters\n",
    "X, _ = make_blobs(n_samples=300, centers=3, random_state=42)\n",
    "\n",
    "# Apply AgglomerativeClustering\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=3)\n",
    "agg_labels = agg_clustering.fit_predict(X)\n",
    "\n",
    "# Calculate Silhouette Coefficient\n",
    "agg_silhouette = silhouette_score(X, agg_labels)\n",
    "\n",
    "print(f'AgglomerativeClustering Silhouette Coefficient: {agg_silhouette:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ba5fa7-159b-45e0-a28a-0292c6288ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
