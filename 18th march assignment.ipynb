{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc5a9170-d2a2-4363-9da9-490ac593c767",
   "metadata": {},
   "source": [
    "Q1. The Filter method in feature selection is a technique used to select relevant features from a dataset before applying a machine learning algorithm. It works by evaluating the statistical properties of each feature independently of the machine learning model. Common filter methods include techniques like correlation analysis, mutual information, chi-squared test, and ANOVA. These methods assign a score or statistical measure to each feature, which is then used to rank or select the most informative features for the model.\n",
    "\n",
    "Q2. The Wrapper method differs from the Filter method in that it evaluates feature subsets by using a specific machine learning model's performance as a criterion. It involves iteratively selecting and evaluating different combinations of features and selecting the subset that yields the best model performance. Common techniques in the Wrapper method include forward selection, backward elimination, and recursive feature elimination (RFE).\n",
    "\n",
    "Q3. Embedded feature selection methods incorporate feature selection as part of the model training process. Some common techniques used in Embedded methods include:\n",
    "L1 regularization (Lasso): Encourages sparsity in linear models by penalizing the absolute values of feature coefficients.\n",
    "Tree-based feature selection: Decision trees and random forests can measure feature importance and select relevant features.\n",
    "Recursive Feature Elimination (RFE) with models like Support Vector Machines (SVM) or Logistic Regression.\n",
    "\n",
    "Q4. Drawbacks of using the Filter method for feature selection include:\n",
    "Independence assumption: Filter methods evaluate features independently and may not consider feature interactions.\n",
    "Limited to feature statistics: They rely solely on statistical measures and may not capture complex relationships in the data.\n",
    "May not optimize model performance: Filter methods don't guarantee that the selected features will result in the best model performance, as they don't consider model-specific criteria.\n",
    "\n",
    "Q5. You might prefer using the Filter method over the Wrapper method in situations where:\n",
    "You have a large dataset with many features, making Wrapper methods computationally expensive.\n",
    "You want a quick and computationally efficient way to remove irrelevant or redundant features.\n",
    "You are more concerned with reducing feature dimensionality than fine-tuning model performance.\n",
    "\n",
    "Q6. To choose the most pertinent attributes for the predictive model of customer churn in a telecom company using the Filter method, you could follow these steps:\n",
    "Compute statistical measures (e.g., correlation, mutual information, chi-squared) for each feature with respect to the target variable (customer churn).\n",
    "Rank the features based on their scores or statistical significance.\n",
    "Select the top-ranked features that exhibit the highest relevance to customer churn.\n",
    "Train your predictive model using the selected features and evaluate its performance.\n",
    "\n",
    "Q7. To select the most relevant features for predicting the outcome of a soccer match using the Embedded method, you could follow these steps:\n",
    "Choose a machine learning model suitable for the task, such as a random forest or gradient boosting.\n",
    "Train the model on the entire dataset, including all features.\n",
    "Examine the feature importances provided by the model, which indicates the contribution of each feature to the model's predictive performance.\n",
    "Select the features with the highest importance scores as the most relevant ones for your prediction model.\n",
    "\n",
    "Q8. To use the Wrapper method for feature selection when predicting the price of a house, you can follow these steps:\n",
    "Define a set of candidate features that might be relevant for predicting house prices (e.g., size, location, age).\n",
    "Create subsets of these features and train your predictive model using each subset.\n",
    "Evaluate the model's performance (e.g., using cross-validation) for each feature subset.\n",
    "Select the subset that results in the best model performance (e.g., lowest Mean Squared Error or highest R-squared value).\n",
    "The selected subset of features will be the ones used in your final house price prediction model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
