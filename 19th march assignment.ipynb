{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63c811c4-54cb-400b-b2d1-6bbf3b324b0d",
   "metadata": {},
   "source": [
    "Q1. Min-Max scaling is a data preprocessing technique used to scale numerical features within a specific range, typically between 0 and 1. It is done by subtracting the minimum value in the feature from each data point and then dividing the result by the range of the feature (i.e., the difference between the maximum and minimum values). This scales the data to the desired range, making it suitable for machine learning algorithms that are sensitive to the scale of features.\n",
    "Example: Suppose you have a dataset of house prices, and you want to scale the \"square footage\" feature using Min-Max scaling. If the minimum square footage is 800 square feet, the maximum is 2500 square feet, and you have a data point with 1500 square feet, Min-Max scaling would transform it as follows:\n",
    "Scaled value = (1500 - 800) / (2500 - 800) = 0.375\n",
    "\n",
    "Q2. Unit Vector scaling, also known as normalization, scales features to have a length of 1. It differs from Min-Max scaling because it doesn't place the data within a specific range but rather ensures that each data point has a magnitude of 1 while preserving the direction of the vector. Unit Vector scaling is often used in situations where the direction of the data points is essential, such as in machine learning algorithms like k-nearest neighbors.\n",
    "Example: In a dataset with numerical features, if you have a data point [3, 4], you would normalize it by dividing each component by the magnitude (Euclidean norm) of the vector, like this:\n",
    "Normalized value = [3/5, 4/5] = [0.6, 0.8]\n",
    "\n",
    "Q3. Principal Component Analysis (PCA) is a dimensionality reduction technique used to reduce the number of features in a dataset while retaining most of the important information. It does this by transforming the original features into a new set of orthogonal features called principal components. These components are ordered by the amount of variance they capture, allowing you to select a subset of them to reduce dimensionality.\n",
    "Example: In a dataset with numerous correlated features, PCA can be used to reduce the dimensionality while retaining most of the variance. For instance, if you have data with 10 features, PCA can transform it into a smaller set of principal components (e.g., 3 components) that capture most of the variance in the original data.\n",
    "\n",
    "Q4. PCA can be used for feature extraction by generating new features (principal components) that are linear combinations of the original features. These new features capture the most important information in the data and can be used as a reduced representation of the original dataset.\n",
    "Example: Let's say you have an image dataset with high-dimensional pixel values. You can apply PCA to extract a set of principal components that represent the most significant patterns in the images. These principal components can be used as a reduced feature set for tasks like image classification or compression.\n",
    "\n",
    "Q5. In a food delivery recommendation system project, you can use Min-Max scaling to preprocess the data as follows:\n",
    "Identify the numerical features in your dataset, such as price, rating, and delivery time.\n",
    "For each numerical feature, calculate the minimum and maximum values.\n",
    "Use the Min-Max scaling formula to scale each feature to the range [0, 1]:\n",
    "Scaled value = (x - min) / (max - min)\n",
    "Apply this scaling to each feature independently, so they all fall within the [0, 1] range. This ensures that no single feature dominates the others due to differences in their original scales.\n",
    "\n",
    "Q6. To reduce the dimensionality of a stock price prediction dataset using PCA:\n",
    "Identify the features in your dataset, including company financial data and market trends.\n",
    "Standardize the features to have a mean of 0 and a standard deviation of 1 to ensure they are on the same scale.\n",
    "Use PCA to transform the standardized features into a set of principal components.\n",
    "Analyze the variance explained by each principal component and decide how many components to retain. A common choice is to retain components that capture a significant portion (e.g., 95%) of the variance.\n",
    "Use the retained principal components as your reduced feature set for building the stock price prediction model.\n",
    "\n",
    "Q7. To perform Min-Max scaling on the dataset [1, 5, 10, 15, 20] and transform the values to a range of -1 to 1, you can use the following formula:\n",
    "Scaled value = 2 * (x - min) / (max - min) - 1\n",
    "Applying this formula to each value in the dataset:\n",
    "For 1: Scaled value = 2 * (1 - 1) / (20 - 1) - 1 = -1\n",
    "For 5: Scaled value = 2 * (5 - 1) / (20 - 1) - 1 ≈ -0.6\n",
    "For 10: Scaled value = 2 * (10 - 1) / (20 - 1) - 1 ≈ 0.2\n",
    "For 15: Scaled value = 2 * (15 - 1) / (20 - 1) - 1 ≈ 0.6\n",
    "For 20: Scaled value = 2 * (20 - 1) / (20 - 1) - 1 = 1\n",
    "\n",
    "Q8. To perform Feature Extraction using PCA on the dataset [height, weight, age, gender, blood pressure], you should follow these steps:\n",
    "\n",
    "Standardize the numerical features (height, weight, and blood pressure) to have a mean of 0 and a standard deviation of 1.\n",
    "Use PCA to transform the standardized features into a set of principal components.\n",
    "Analyze the variance explained by each principal component.\n",
    "Choose the number of principal components to retain based on the variance explained. A common rule of thumb is to retain enough components to capture a significant portion of the total variance (e.g., 95%).\n",
    "The number of principal components to retain may vary based on the dataset, but for this example, let's say you choose to retain 2 principal components.\n",
    "In this case, you would retain 2 principal components because they capture most of the variance while reducing the dimensionality of your dataset. These retained components can be used as a reduced feature set for further analysis or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2d3373-ad33-47f4-af98-6f03a4e24f14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
